{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp spectrogram_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram Processor\n",
    "\n",
    "> Commandline program to generate spectrograms from audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argparse [load filename ref](https://www.reddit.com/r/learnpython/comments/575rbb/confused_how_to_set_inputoutput_file_paths_with/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from fastprogress import progress_bar\n",
    "from os import uname\n",
    "from fastcore.parallel import parallel\n",
    "from fastcore.parallel import num_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# ignore librosa pysoundfile load warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=UserWarning,\n",
    "    module=r'librosa'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path to configuration file. *Note*: looks like commandline programs take path inputs relative to the console's address, not the program's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--path\", help=\"parameter filepath\", nargs=1)\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args([\"--path\", \"parameters.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "fpath = Path(args.path[0])\n",
    "assert fpath.exists(), (f\"Filepath '{fpath}' not found.\")\n",
    "assert fpath.is_file(), (f\"'{fpath}' is not a valid file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit and Save Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# # testing\n",
    "# # p = str((Path()/'sample_data').absolute())\n",
    "\n",
    "# parameters = {\n",
    "#     'n_fft':2048,\n",
    "#     'hop_length':512,\n",
    "#     'n_mels':256,\n",
    "#     'mel_n_fft_override':None,\n",
    "#     'mel_hop_length_override':None,\n",
    "#     'path':'/home/jupyter/data',\n",
    "# #     'path':p,\n",
    "#     'audio_folders':['train','test'],\n",
    "#     'codecs':['.flac'],\n",
    "#     'serial':False\n",
    "# }\n",
    "# # save\n",
    "# with open('parameters.json', 'w') as file:\n",
    "#     json.dump(parameters, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters file \"parameters.json\" loaded.\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "with open(fpath, 'r') as file:\n",
    "    parameters = json.load(file)\n",
    "    print(f\"Parameters file \\\"{fpath}\\\" loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "num_cpus = num_cpus() # func â†’ int\n",
    "serial = True if uname().sysname.lower() != 'linux' else parameters['serial'] # no parallelization support on MacOS or Windows\n",
    "\n",
    "n_fft = parameters['n_fft']\n",
    "hop_length = parameters['hop_length']\n",
    "n_mels = parameters['n_mels']\n",
    "\n",
    "mel_n_fft = parameters['mel_n_fft_override']\n",
    "if mel_n_fft == None: mel_n_fft = n_fft\n",
    "\n",
    "mel_hop_length = parameters['mel_hop_length_override']\n",
    "if mel_hop_length == None: mel_hop_length = hop_length\n",
    "\n",
    "if n_fft / n_mels < 2**3:\n",
    "    print(f\"Warning: N FFT ({n_fft}) is fewer than 3 powers of 2 greater than N Mels ({n_mels}).\"\n",
    "          f\" This may result in null values at lower mels in spectrograms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_spectrogram(wf, n_fft=1024, hop_length=512):\n",
    "    return librosa.power_to_db(np.abs(librosa.stft(wf, n_fft=n_fft, hop_length=hop_length))**2)\n",
    "    \n",
    "def compute_mel_spectrogram(wf, sr=None, n_fft=1024, hop_length=512, n_mels=128):\n",
    "    return librosa.power_to_db(librosa.feature.melspectrogram(wf, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels))\n",
    "\n",
    "def write_spectrogram(spgm, filepath):\n",
    "    # convert fp32 array to 0-255 UInt8.\n",
    "    shift = abs(spgm.min()) if spgm.min() < 0 else 0.0\n",
    "    x = ((spgm + shift) * (255/(shift + spgm.max())))\n",
    "    img = Image.fromarray(x.round().astype(np.uint8)[::-1]) # vertical flip\n",
    "    img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_compute_write(audio_file, diagnostic_suffix=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    For parallelization.\n",
    "    \"\"\"\n",
    "    wf,sr = librosa.load(audio_file, sr=None)\n",
    "    spgm_frq = compute_spectrogram(wf, n_fft=n_fft, hop_length=hop_length)\n",
    "    spgm_mel = compute_mel_spectrogram(wf, sr=sr, n_fft=mel_n_fft, hop_length=mel_hop_length, n_mels=n_mels)\n",
    "    write_spectrogram(spgm_frq, path_spgm_frq/f\"{audio_file.stem}{diagnostic_suffix}.png\")\n",
    "    write_spectrogram(spgm_mel, path_spgm_mel/f\"{audio_file.stem}{diagnostic_suffix}.png\")\n",
    "#     return {'audio_file':audio_file.stem,'spgm_frq':spgm_frq,'spgm_mel':spgm_mel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# times = {'compute':[],'write':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spgms_para = []\n",
    "# spgms_seri = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelization ON with 8 cores.\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "extratext = [f\" with {num_cpus} core{['','s'][num_cpus>1]}\",\"\"][serial]\n",
    "print(f\"Parallelization {['ON','OFF'][serial]}{extratext}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 01:29<00:00 processing: train/287630bbe.flac]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 1.7 s, total: 2min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "path = Path(parameters['path'])\n",
    "path_spgm_frq = path/'spectrogram_frq'\n",
    "path_spgm_frq.mkdir(parents=True, exist_ok=True)\n",
    "path_spgm_mel = path/'spectrogram_mel'\n",
    "path_spgm_mel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# get list of audio files\n",
    "audio_files = []\n",
    "for audio_folder in parameters['audio_folders']:\n",
    "    audio_path = path/audio_folder\n",
    "    audio_files += [file for file in audio_path.iterdir() if file.suffix in parameters['codecs']]\n",
    "    \n",
    "# load waveform\n",
    "if serial:\n",
    "    pb = progress_bar(audio_files)\n",
    "    for audio_file in pb:\n",
    "        pb.comment = f\"processing: {audio_file.parent.name}/{audio_file.name}\"\n",
    "        wf,sr = librosa.load(audio_file, sr=None)\n",
    "        # compute freq & mel spectrograms\n",
    "        spgm_frq = compute_spectrogram(wf, n_fft=n_fft, hop_length=hop_length)\n",
    "        spgm_mel = compute_mel_spectrogram(wf, sr=sr, n_fft=mel_n_fft, hop_length=mel_hop_length, n_mels=n_mels)\n",
    "        # write spectrograms\n",
    "        write_spectrogram(spgm_frq, path_spgm_frq/f\"{audio_file.stem}.png\")\n",
    "        write_spectrogram(spgm_mel, path_spgm_mel/f\"{audio_file.stem}.png\")\n",
    "else:\n",
    "    _ = parallel(load_compute_write, audio_files, \n",
    "            **{'n_fft':n_fft,'hop_length':hop_length,'n_mels':n_mels}, threadpool=True, n_workers = num_cpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "print(f\"\\n{len(audio_files)} files processed in {time.strftime('%H:%M:%S', time.gmtime(time.time() - t))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## development testing\n",
    "\n",
    "---\n",
    "\n",
    "TODO: incorporate into tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # export\n",
    "# path = Path(parameters['path'])\n",
    "# path_spgm_frq = path/'spectrogram_frq'\n",
    "# path_spgm_frq.mkdir(parents=True, exist_ok=True)\n",
    "# path_spgm_mel = path/'spectrogram_mel'\n",
    "# path_spgm_mel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # get list of audio files\n",
    "# audio_files = []\n",
    "# for audio_folder in parameters['audio_folders']:\n",
    "#     audio_path = path/audio_folder\n",
    "#     audio_files += [file for file in audio_path.iterdir() if file.suffix in parameters['codecs']]\n",
    "    \n",
    "# # load waveform\n",
    "# if serial:\n",
    "#     pb = progress_bar(audio_files[:100])\n",
    "#     for audio_file in pb:\n",
    "#         pb.comment = f\"processing: {audio_file.parent.name}/{audio_file.name}\"\n",
    "#         wf,sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "#         # compute freq & mel spectrograms\n",
    "#         spgm_frq = compute_spectrogram(wf, n_fft=n_fft, hop_length=hop_length)\n",
    "#         spgm_mel = compute_mel_spectrogram(wf, sr=sr, n_fft=mel_n_fft, hop_length=mel_hop_length, n_mels=n_mels)\n",
    "\n",
    "#         # write spectrograms\n",
    "#         write_spectrogram(spgm_frq, path_spgm_frq/f\"{audio_file.stem}.png\")\n",
    "#         write_spectrogram(spgm_mel, path_spgm_mel/f\"{audio_file.stem}.png\")\n",
    "\n",
    "#         # verify same values parallel vs. serial (note: ensure same audios)\n",
    "#     #     assert np.alltrue(spgm_frq == para_dict[audio_file.stem]['spgm_frq'])\n",
    "#     #     assert np.alltrue(spgm_mel == para_dict[audio_file.stem]['spgm_mel'])\n",
    "# else:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for verifying computes parallel vs. serial\n",
    "# results = parallel(load_and_compute, audio_files[:100], **{'n_fft':n_fft,'hop_length':hop_length,'n_mels':n_mels}, threadpool=True)\n",
    "# para_dict = {res['audio_file']:{'spgm_frq':res['spgm_frq'],'spgm_mel':res['spgm_mel']} for res in results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 23 s, total: 3min 8s\n",
      "Wall time: 26.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#100) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# parallel(load_compute_write, audio_files[:100], **{'n_fft':n_fft,'hop_length':hop_length,'n_mels':n_mels,'diagnostic_suffix':\"para\"}, threadpool=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verify writes parallel vs. serial\n",
    "# for path_spgm in (path_spgm_frq, path_spgm_mel):\n",
    "#     files = list(path_spgm.iterdir())\n",
    "#     files_s = sorted([f for f in files if 'para' not in f.stem])\n",
    "#     files_p = sorted([f for f in files if 'para' in f.stem])\n",
    "#     for f in files_p: assert f.stem[:-4] in map(lambda x: x.stem, files_s)\n",
    "#     for fp in files_p:\n",
    "#         fs = [f for f in files_s if f.stem == fp.stem[:-4]][0]\n",
    "#         im_p = Image.open(fp)\n",
    "#         im_s = Image.open(fs)\n",
    "#         ar_s = np.asarray(im_s)\n",
    "#         ar_p = np.asarray(im_p)\n",
    "#         assert np.alltrue(ar_s == ar_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spgm_frq = parallel(compute_spectrogram, [wf], **{'n_fft':n_fft,'hop_length':hop_length})\n",
    "# spgm_mel = parallel(compute_mel_spectrogram, [wf], **{'sr':sr,'n_fft':mel_n_fft,'hop_length':mel_hop_length,'n_mels':n_mels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check parallels equal serials\n",
    "# assert np.alltrue([np.alltrue(np.array(para) == np.array(seri)) for para,seri in zip(spgms_para,spgms_seri)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='30' class='' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [30/30 00:07<00:00 processing: 009fbc7b4.flac]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # export\n",
    "# path = Path(parameters['path'])\n",
    "# path_spgm_frq = path/'spectrogram_frq'\n",
    "# path_spgm_frq.mkdir(parents=True, exist_ok=True)\n",
    "# path_spgm_mel = path/'spectrogram_mel'\n",
    "# path_spgm_mel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # get list of audio files\n",
    "# audio_files = []\n",
    "# for audio_folder in parameters['audio_folders']:\n",
    "#     audio_path = path/audio_folder\n",
    "#     audio_files += [file for file in audio_path.iterdir() if file.suffix in parameters['codecs']]\n",
    "    \n",
    "# # load waveform\n",
    "# pb = progress_bar(audio_files)\n",
    "# for audio_file in pb:\n",
    "#     pb.comment = f\"processing: {audio_file.parent.name}/{audio_file.name}\"\n",
    "#     wf,sr = librosa.load(audio_file, sr=None)\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "#     # compute freq & mel spectrograms\n",
    "#     spgm_frq = compute_spectrogram(wf, n_fft=n_fft, hop_length=hop_length)\n",
    "#     spgm_mel = compute_mel_spectrogram(wf, sr, n_fft=mel_n_fft, hop_length=mel_hop_length, n_mels=n_mels)\n",
    "\n",
    "#     # write spectrograms\n",
    "#     write_spectrogram(spgm_frq, path_spgm_frq/f\"{audio_file.stem}.png\")\n",
    "#     write_spectrogram(spgm_mel, path_spgm_mel/f\"{audio_file.stem}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# # custom write\n",
    "# t_compute = np.array(times['compute'])\n",
    "# t_write = np.array(times['write'])\n",
    "# estim = (t_compute.mean() + t_write.mean()) * (1992+4727)\n",
    "# print(t_compute.sum(), t_compute.mean())\n",
    "# print(t_write.sum(), t_write.mean())\n",
    "# print(estim)\n",
    "# print(spgm_frq.shape, spgm_mel.shape)\n",
    "# time.strftime('%H:%M:%S', time.gmtime(estim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_spectrogram_processor.ipynb.\n",
      "Converted experiments - spectrogram compression and timing statistics.ipynb.\n",
      "Converted experiments - waveform analysis.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## asides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate way to show progress bars. `progress_bar` is subordinated to a `master_bar` instance, `mb`. `mb` is a single-run loop, and used for writing comments. The only issue is this prints a default message \"Epoch i/N\" with each progress bar loop. If using only a `progress_bar`, you'll have to instatiate it in order to print comments/updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb = master_bar(range(1))\n",
    "# for itr in mb:\n",
    "#     for audio_file in progress_bar(audio_files, parent=mb):\n",
    "# #         mb.main_bar.comment = \"\"\n",
    "#         mb.child.comment = f\"processing: {audio_file.name}\"\n",
    "# #         mb.write(f\"\")\n",
    "# #         print(f\"processing: {audio_file.name}\")\n",
    "#         time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
