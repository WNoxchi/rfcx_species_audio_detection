# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['compute_spectrogram', 'compute_mel_spectrogram', 'display_detection_window_waveform',
           'get_annotation_length']

# Cell
import numpy as np
import librosa

# Cell
def compute_spectrogram(wf, n_fft, hop_length):
    return librosa.power_to_db(np.abs(librosa.stft(wf, n_fft=n_fft, hop_length=hop_length))**2)

def compute_mel_spectrogram(wf, sr, n_fft, hop_length, n_mels):
    return librosa.power_to_db(librosa.feature.melspectrogram(wf, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels))


# Cell
def display_detection_window_waveform(rec_id,csv_fpath,audio_path,codec='flac',figsize=(20,10)):
    # load
    wf,sr = librosa.load(audio_path/f'{rec_id}.{codec}', sr=None)
    csv_file = pd.read_csv(csv_fpath)
    t_min,t_max = csv_file.loc[csv_file['recording_id']==rec_id].loc[:,['t_min','t_max']].values[0]
    # full waveform
    plt.figure(figsize=figsize)
    plt.axvline(x=int(sr*t_min), color='r'); plt.axvline(x=int(sr*t_max), color='r')
    plt.title(f'{audio_path.name} waveform')
    plt.plot(wf)
    # zoomed waveform
    plt.figure(figsize=(20,10))
    plt.title(f'{audio_path.name} detection')
    plt.plot(wf[int(sr*t_min):int(sr*t_max)], linewidth=0.5)

# Cell
def get_annotation_length(csv_file, rec_id):
    t_min,t_max = csv_file.loc[csv_file['recording_id']==rec_id].loc[:,['t_min','t_max']].values[0]
    return t_max - t_min